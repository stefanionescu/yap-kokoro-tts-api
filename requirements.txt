fastapi>=0.115.0,<0.116.0
uvicorn[standard]>=0.30.0,<0.31.0
python-dotenv==1.0.1

# Numpy pinned to <2 to avoid ABI issues with compiled wheels in CUDA stacks
numpy==1.26.4

# PyTorch stack for vLLM 0.10.0 (CUDA 12.1 wheels)
torch==2.5.1
torchvision==0.20.1
xformers==0.0.28.post3

# vLLM with DeepSpeed FP6/FP8 support
vllm==0.10.0

# Transformers + vision extras
transformers==4.55.1
accelerate==0.28.0
pillow
timm==0.9.16

# SNAC decoder
snac==1.2.1

pydantic>=2.7.0,<3
httptools==0.6.1
setuptools==69.1.1
tqdm==4.66.2
websockets==12.0

# DeepSpeed runtime for deepspeedfp quantization
deepspeed==0.17.4
