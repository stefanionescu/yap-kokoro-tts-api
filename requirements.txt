fastapi==0.109.2
uvicorn[standard]==0.27.1
python-dotenv==1.0.1

# Numpy pinned to <2 to avoid ABI issues with compiled wheels in CUDA stacks
numpy==1.26.4

# PyTorch stack pinned to a compatible set for CUDA 12.1 and vLLM 0.4.x
torch==2.4.1
torchvision==0.19.1
xformers==0.0.27.post2

# vLLM with DeepSpeed FP6/FP8 support
vllm==0.4.0

# Transformers + vision extras (avoid old versions missing vision models)
transformers==4.55.1
accelerate==0.28.0
pillow
timm==0.9.16

# SNAC decoder
snac==1.2.1

pydantic==2.6.1
httptools==0.6.1
setuptools==69.1.1
tqdm==4.66.2
websockets==12.0

# DeepSpeed runtime for deepspeedfp quantization
deepspeed>=0.11.0
